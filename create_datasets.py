import os
from typing import List, Optional
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
load_dotenv()

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")


model = ChatOpenAI(model="gpt-3.5-turbo-0125", openai_api_key=OPENAI_API_KEY)

class PolicyDoc(BaseModel):
    """A class to represent a policy document."""
    name: str = Field(..., description="The name of the document.")
    section: str = Field(..., description="The section of the document.")
    text: str = Field(..., description="The text content of the document.")
    url: Optional[str] = Field(None, description="The URL of the document.")

class Data(BaseModel):
    """Extracted data about document."""

    # Creates a model so that we can extract multiple entities.
    policies: List[PolicyDoc]


def perform_extraction(raw_text: str):
    extract_prompt = ChatPromptTemplate.from_messages(
        [
            "system",
                "You are an expert extraction algorithm. "
                "Only extract relevant information from the text. "
                "If you do not know the value of an attribute asked to extract, "
                "return null for the attribute's value.",
                ("human", "{text}"),
        ]
    )

    llm = ChatOpenAI(model="gpt-3.5-turbo-0125", openai_api_key=OPENAI_API_KEY)

    runnable = extract_prompt | llm.with_structured_output(schema=PolicyDoc)
    extracted_data = runnable.invoke({"text": raw_text})
    perform_secondary_extraction([extracted_data])
    return extracted_data


class ParsedDoc(BaseModel):
    """A class to represent a parsed document."""
    input: str = Field(..., description="A question given by a human.")
    instruction: str = Field(..., description="The instruction given to the AI assistant.")
    output: str = Field(..., description="The output generated by the AI assistant.")

class Dataset(BaseModel):
    """A class to represent a dataset."""
    data: List[ParsedDoc]

    def to_dict(self):
        return self.dict()

def perform_secondary_extraction(policies: List[PolicyDoc]):
    secondary_prompt = ChatPromptTemplate.from_messages(
        [
            "system",
                "You are an expert in generating training datasets. You understand the need for accurate and relevant information."
                "When creating datasets, you attempt to create as many human/assistant qa pairs per section of the document as possible. The dataset should be in context of the given materials."
                "The goal is to generate a dataset that can be used to train an LLM model to answer questions about the  documents."
                "Generate an LLM training dataset using the following JSON format: 'input' : <input>, 'instruction' : <instruction>, 'output': <output>.",
                ("human", "{text}"),
        ]
    )
    dataset = []
    llm = ChatOpenAI(model="gpt-3.5-turbo-0125", openai_api_key=OPENAI_API_KEY)
    for policy in policies:
        runnable = secondary_prompt | llm.with_structured_output(schema=Dataset)
        dataset.append(runnable.invoke({"text": policy.text}).to_dict())
      
    return dataset